{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Прогнозирование индекса селективности (SI) методом бинарной классификации\n",
    "\n",
    "**Цель проекта:** Разработать модель машинного обучения для классификации химических соединений на два класса в зависимости от того, превышает ли их **индекс селективности (SI)** медианное значение.\n",
    "\n",
    "**Контекст:** Индекс селективности является важным параметром, который отражает, насколько избирательно соединение действует на целевую клетку (например, раковую) по сравнению с нецелевыми (здоровыми). Высокий SI желателен для минимизации побочных эффектов. Прогнозирование этого показателя помогает в отборе наиболее перспективных кандидатов в лекарства.\n",
    "\n",
    "**План работы:**\n",
    "1.  **Загрузка и подготовка данных:** Загрузка датасета, создание целевой бинарной переменной на основе медианы SI.\n",
    "2.  **Разведочный анализ данных (EDA):** Анализ распределения целевой переменной для проверки сбалансированности классов.\n",
    "3.  **Предобработка данных:** Разделение выборки на обучающую и тестовую, а также масштабирование признаков.\n",
    "4.  **Обучение и подбор гиперпараметров:** Использование модели `RandomForestClassifier` и поиск оптимальных гиперпараметров с помощью `GridSearchCV`.\n",
    "5.  **Оценка модели:** Комплексная оценка производительности итоговой модели на тестовой выборке.\n",
    "6.  **Анализ важности признаков:** Определение молекулярных дескрипторов, вносящих наибольший вклад в прогноз.\n",
    "7.  **Выводы и рекомендации:** Итоговый анализ результатов и определение дальнейших шагов."
   ],
   "metadata": {
    "id": "intro_section_si"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Загрузка библиотек и данных"
   ],
   "metadata": {
    "id": "libs_and_data_loading_header_si"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports_si"
   },
   "outputs": [],
   "source": [
    "# Основные библиотеки для анализа данных\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Модели и метрики\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "\n",
    "# Настройки для отображения\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_loading_si"
   },
   "outputs": [],
   "source": [
    "# ЗАМЕЧАНИЕ: Замените 'df_bioactivity_data_preprocessed_2_class_pSI.csv' на реальный путь к вашему файлу.\n",
    "# Для примера, создадим синтетический датасет, схожий по структуре, и используем важные признаки из вашего ноутбука.\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "important_features = [\n",
    "    'BCUT2D_MRLOW', 'BCUT2D_MWLOW', 'VSA_EState4', 'BCUT2D_LOGPHI', 'MinEStateIndex', \n",
    "    'MolLogP', 'SlogP_VSA3', 'NumHAcceptors', 'MaxAbsEStateIndex', 'MinAbsEStateIndex'\n",
    "]\n",
    "other_features = [f'feature_{i}' for i in range(190)]\n",
    "feature_names = important_features + other_features\n",
    "\n",
    "X, y_reg = make_classification(n_samples=500, n_features=200, n_informative=10, n_redundant=5, random_state=42)\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['SI'] = y_reg + np.random.normal(0, 0.5, size=y_reg.shape) # Имитация регрессионной цели SI\n",
    "\n",
    "print(\"Размер датасета:\", df.shape)\n",
    "print(\"Первые 5 строк данных:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Создание целевой переменной\n",
    "Для решения задачи бинарной классификации преобразуем непрерывную переменную `SI` в категориальную `SI_class`. Порогом для разделения служит медиана."
   ],
   "metadata": {
    "id": "target_variable_creation_markdown_si"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "target_variable_creation_code_si"
   },
   "outputs": [],
   "source": [
    "median_si = df['SI'].median()\n",
    "print(f\"Медианное значение SI: {median_si:.4f}\")\n",
    "\n",
    "# Создаем целевую переменную 'SI_class': 1 если SI > медианы, иначе 0\n",
    "df['SI_class'] = (df['SI'] > median_si).astype(int)\n",
    "\n",
    "# Удаляем исходный столбец SI, чтобы избежать утечки данных\n",
    "df_model = df.drop('SI', axis=1)\n",
    "\n",
    "print(\"\\nРаспределение классов в новой целевой переменной:\")\n",
    "df_model['SI_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Разведочный анализ данных (EDA)"
   ],
   "metadata": {
    "id": "eda_header_si"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eda_plot_si"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.countplot(x='SI_class', data=df_model, palette='pastel')\n",
    "plt.title('Распределение классов целевой переменной (SI_class)')\n",
    "plt.xlabel('Класс SI (0: <= медианы, 1: > медианы)')\n",
    "plt.ylabel('Количество')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Вывод по EDA:** Как и ожидалось, использование медианы в качестве порога привело к идеально сбалансированным классам. Это упрощает процесс моделирования, так как нет необходимости в применении техник для борьбы с дисбалансом."
   ],
   "metadata": {
    "id": "eda_conclusion_si"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Подготовка данных к обучению"
   ],
   "metadata": {
    "id": "preprocessing_header_si"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_split_si"
   },
   "outputs": [],
   "source": [
    "# Определение признаков (X) и целевой переменной (y)\n",
    "X = df_model.drop('SI_class', axis=1)\n",
    "y = df_model['SI_class']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "# Используем стратификацию (stratify=y), чтобы сохранить исходное распределение классов в обеих выборках\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Масштабирование признаков\n",
    "Приводим все признаки к единому масштабу с помощью `StandardScaler`. Это стандартная процедура, которая, хоть и не является строго обязательной для древовидных моделей, обеспечивает универсальность подхода и является хорошей практикой.\n",
    "\n",
    "**Важно:** Обучаем `StandardScaler` (`.fit()`) только на тренировочных данных (`X_train`), а затем применяем (`.transform()`) его и к тренировочным, и к тестовым данным. Это предотвращает утечку информации о распределении тестовой выборки в процесс обучения."
   ],
   "metadata": {
    "id": "scaling_markdown_si"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scaling_code_si"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Преобразуем обратно в DataFrame для удобства и сохранения названий колонок\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Обучение модели и подбор гиперпараметров\n",
    "\n",
    "Используем `RandomForestClassifier` как основной алгоритм. Это ансамблевая модель, состоящая из множества деревьев решений, что делает её устойчивой к переобучению и способной улавливать сложные нелинейные зависимости. Оптимальные гиперпараметры ищем с помощью `GridSearchCV`."
   ],
   "metadata": {
    "id": "training_header_si"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grid_search_si"
   },
   "outputs": [],
   "source": [
    "# Определяем модель\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "# Задаем сетку гиперпараметров для поиска (основываясь на исходном ноутбуке)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],      # Количество деревьев\n",
    "    'max_depth': [5, 10, 20, None],        # Максимальная глубина\n",
    "    'min_samples_split': [2, 5, 10]     # Мин. число образцов для разделения\n",
    "}\n",
    "\n",
    "# Используем стратифицированную кросс-валидацию для сохранения баланса классов в фолдах\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Настраиваем GridSearchCV для поиска по сетке с оценкой по ROC-AUC\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, \n",
    "                         cv=cv, n_jobs=-1, verbose=2, scoring='roc_auc')\n",
    "\n",
    "# Запускаем поиск\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nЛучшие параметры, найденные GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Сохраняем лучшую модель\n",
    "best_rf_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Оценка качества лучшей модели\n",
    "\n",
    "Оцениваем производительность модели с оптимальными параметрами на тестовой выборке. Это позволяет получить объективное представление о том, как модель будет работать на новых, невиданных ранее данных."
   ],
   "metadata": {
    "id": "evaluation_header_si"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluation_metrics_si"
   },
   "outputs": [],
   "source": [
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred = best_rf_model.predict(X_test_scaled)\n",
    "y_pred_proba = best_rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Рассчитываем метрики\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Оценки метрик на тестовых данных:\")\n",
    "print(f\"- Accuracy: {accuracy:.4f}\")\n",
    "print(f\"- F1-score: {f1:.4f}\")\n",
    "print(f\"- ROC-AUC:  {roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nДетальный отчет по классификации (Classification Report):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Визуализация результатов\n",
    "**Матрица ошибок (Confusion Matrix)** показывает количество верных и неверных предсказаний для каждого класса. **ROC-кривая** иллюстрирует качество модели при разных порогах отсечения."
   ],
   "metadata": {
    "id": "visualization_markdown_si"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualization_code_si"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. Матрица ошибок\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=axes[0])\n",
    "axes[0].set_title('Матрица ошибок (Confusion Matrix)')\n",
    "axes[0].set_xlabel('Предсказанные классы')\n",
    "axes[0].set_ylabel('Истинные классы')\n",
    "\n",
    "# 2. ROC-кривая\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "axes[1].plot(fpr, tpr, color='green', lw=2, label=f'ROC-кривая (AUC = {roc_auc:.2f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC-кривая')\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Анализ важности признаков\n",
    "Оценим вклад каждого признака в итоговую модель. Это помогает понять, какие именно молекулярные свойства наиболее сильно связаны с индексом селективности."
   ],
   "metadata": {
    "id": "feature_importance_header_si"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feature_importance_code_si"
   },
   "outputs": [],
   "source": [
    "# Создаем DataFrame с важностью признаков\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Отображаем топ-15 самых важных признаков\n",
    "top_n = 15\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importances.head(top_n), palette='plasma')\n",
    "plt.title(f'Топ-{top_n} наиболее важных признаков')\n",
    "plt.xlabel('Важность (Gini Importance)')\n",
    "plt.ylabel('Признак (Молекулярный дескриптор)')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nСписок топ-{top_n} признаков:\")\n",
    "print(feature_importances.head(top_n).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Выводы и рекомендации\n",
    "\n",
    "#### Результаты\n",
    "Была разработана и оценена модель `RandomForestClassifier` для прогнозирования класса индекса селективности (SI). На основе данных из оригинального ноутбука, оптимальная модель показала на тестовой выборке следующие **умеренные** результаты:\n",
    "- **`Accuracy`**: ~0.67\n",
    "- **`F1-score`**: ~0.64\n",
    "- **`ROC-AUC`**: ~0.74\n",
    "\n",
    "**Интерпретация метрик:**\n",
    "- **ROC-AUC** на уровне 0.74 показывает, что модель обладает способностью к различению классов значительно лучше, чем случайное угадывание (AUC=0.5), но ее предсказательная сила не является высокой. \n",
    "- **Accuracy** (67%) и **F1-score** (64%) говорят о том, что модель правильно классифицирует примерно 2 из 3 соединений. F1-score, будучи гармоническим средним точности и полноты, подтверждает, что качество предсказаний для обоих классов сопоставимо, но не идеально.\n",
    "\n",
    "#### Анализ применимости\n",
    "Учитывая умеренное качество, данная модель может быть полезна для **самого первого, грубого отсева** соединений. Она может помочь сузить поле для поиска, отбросив часть заведомо бесперспективных кандидатов, но на нее нельзя полагаться как на основной инструмент принятия решений. Высока вероятность как ложноположительных (соединение будет помечено как перспективное, но на деле таковым не является), так и ложноотрицательных срабатываний.\n",
    "\n",
    "Анализ важности признаков, тем не менее, представляет ценность, так как подсвечивает дескрипторы (`BCUT2D_MRLOW`, `BCUT2D_MWLOW` и др.), которые могут быть важны для понимания структуры соединений с высоким SI.\n",
    "\n",
    "#### Рекомендации по дальнейшему улучшению\n",
    "1.  **Проверка данных и признаков:** Связь между доступными признаками и индексом селективности может быть слабой. Стоит рассмотреть возможность генерации новых, более информативных признаков (feature engineering) или поиска дополнительных данных.\n",
    "2.  **Использование более мощных моделей:** Необходимо протестировать алгоритмы градиентного бустинга (`XGBoost`, `LightGBM`, `CatBoost`). Они часто превосходят случайный лес на структурированных данных и могут лучше уловить сложные зависимости.\n",
    "3.  **Более сложная постановка задачи:** Возможно, бинарная классификация по медиане является слишком грубым упрощением. Стоит рассмотреть **задачу регрессии** (прямое предсказание значения SI) или многоклассовую классификацию (например, 'низкий', 'средний', 'высокий' SI), чтобы получать более детальные прогнозы."
   ],
   "metadata": {
    "id": "conclusions_si"
   }
  }
 ]
}